{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Option 1 :** Using 100% of data for train the model and the same data to test the model is not a very good approach.\n",
    "- **Option 2 :** Split available dataset into training and test sets is a better approach. But if the train and test split is completly different i.e the model has not learned anything related to test data and the prediction can go wrong.\n",
    "- **Kfold Cross Validation :** We divide the data in folds.\n",
    "i.e. suppose we have 100 samples we devide it in 5 folds of 20 sample each and we run multiple iteration like first use 1st fold of sample as test and rest 4 folds for training and note the score, then use 2nd fold of sample as test and rest as training samples then note the score, at last use 5th fold ast est and rest as training and again note the score. At last we average out the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(digits.data, digits.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\utkarsh.alpuria\\Desktop\\My Work\\Python\\Python ML\\Python ML Algorithm\\.ml_algo_py_venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9537037037037037"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "lr.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907407407407407"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Support Vector Machine\n",
    "svm = SVC()\n",
    "svm.fit(X_train, Y_train)\n",
    "svm.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, Y_train)\n",
    "rf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you run train_test_split multiple time the score will change for every model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 3)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8] [0 1 2]\n",
      "[0 1 2 6 7 8] [3 4 5]\n",
      "[0 1 2 3 4 5] [6 7 8]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train, X_test, Y_train, Y_test):\n",
    "    model.fit(X_train,Y_train)\n",
    "    return model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kFold and StratifiedKFold are same thing\n",
    "# StratifiedKFold is for suppose different flowers(category) it maintain equilibrium while creating fold so that train and test data have even categories\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# folds = StratifiedKFold(n_splits=3) \n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\utkarsh.alpuria\\Desktop\\My Work\\Python\\Python ML\\Python ML Algorithm\\.ml_algo_py_venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\utkarsh.alpuria\\Desktop\\My Work\\Python\\Python ML\\Python ML Algorithm\\.ml_algo_py_venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\utkarsh.alpuria\\Desktop\\My Work\\Python\\Python ML\\Python ML Algorithm\\.ml_algo_py_venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\utkarsh.alpuria\\Desktop\\My Work\\Python\\Python ML\\Python ML Algorithm\\.ml_algo_py_venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\utkarsh.alpuria\\Desktop\\My Work\\Python\\Python ML\\Python ML Algorithm\\.ml_algo_py_venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9277777777777778, 0.8666666666666667, 0.9387186629526463, 0.935933147632312, 0.9080779944289693]\n",
      "[0.9694444444444444, 0.9472222222222222, 0.9832869080779945, 0.9888579387186629, 0.9415041782729805]\n",
      "[0.9444444444444444, 0.925, 0.9637883008356546, 0.9749303621169917, 0.935933147632312]\n"
     ]
    }
   ],
   "source": [
    "scores_lr = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "\n",
    "for train_index, test_index in kf.split(digits.data):\n",
    "    X_train, X_test, Y_train, Y_test = digits.data[train_index], digits.data[test_index], digits.target[train_index], digits.target[test_index]\n",
    "\n",
    "    scores_lr.append(get_score(LogisticRegression(), X_train, X_test,  Y_train, Y_test))\n",
    "    scores_svm.append(get_score(SVC(), X_train, X_test,  Y_train, Y_test))\n",
    "    scores_rf.append(get_score(RandomForestClassifier(), X_train, X_test,  Y_train, Y_test))\n",
    "\n",
    "print(scores_lr)\n",
    "print(scores_svm)\n",
    "print(scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96111111, 0.94444444, 0.98328691, 0.98885794, 0.93871866])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR use inbuilt cross val method of sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(SVC(), digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86111111, 0.83055556, 0.8913649 , 0.88300836, 0.82729805])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we compared different estimators\n",
    "# we can also compare same estimator with different parameters, for tuning\n",
    "\n",
    "cross_val_score(RandomForestClassifier(n_estimators=5), digits.data, digits.target) # 5 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91111111, 0.89722222, 0.95821727, 0.95821727, 0.9275766 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators=20), digits.data, digits.target) # 20 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91944444, 0.91111111, 0.95543175, 0.94986072, 0.91364903])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators=40), digits.data, digits.target) # 40 trees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml_algo_py_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
